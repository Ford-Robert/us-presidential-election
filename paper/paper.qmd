---
title: "Forecasting the United States 2024 Presidential Election"
subtitle: "Kamala Harris wins 60th presidency with 265 Electoral College Votes"
author: 
  - Robert Ford
  - Michelle Ji
  - Cher Ning
thanks: "Code and data are available at: https://github.com/Ford-Robert/us-presidential-election."
date: today
date-format: long
abstract: "This report analyzes compiled polling surveys for the 2024 U.S. presidential election using FiveThirtyEight data [@538data] and the 'pool of polls' method. From the analysis, bayesian and generalized linear models were built to forecast the outcome of the presidential election based on popular vote and the electoral college system. The models forecast Kamala Harris as the winner of election, winning 265 electoral college votes versus the 172 votes Donald Trump acquires. Election forecasting is crucial for informing voters, guiding campaign strategies, and engaging the public in the electoral process. Additionally, it helps predict potential policy shifts and holds political institutions accountable, contributing to a more transparent and informed democracy."
format: pdf
header-includes:
  - \usepackage{geometry}
  - \geometry{margin=0.75in} 
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(kableExtra)
library(ggplot2)
library(here)
library(kableExtra)

#read in cleaned data
cleaned_poll_data <-
  read_csv(file = here("data/cleaned_poll_data.csv"), 
           show_col_types = FALSE)
```


# Introduction {#sec-intro}

Every four years, the United States presidential election occurs and is one of the most significant political events internationally. The complex process of the election involves both the popular and electoral college system. The candidate that receives the popular vote by the voters wins the electoral votes for that state [@electoralcollege]. After the popular vote is accounted for, the candidate who receives the majority of the electoral votes from all states wins the presidential election. The number of electoral votes varies by state and is proportional to each state’s respective population [@electoralcollege]. 

Specifically for the 2024 presidential election, the top candidates include Donald Trump and Kamala Harris, both with differing opinions on key topics such as immigration, technology, abortion, and transatlantic affairs. For example, regarding technology, both parties are concerned with the rapid progression of artificial intelligence’s capabilities but differ in the response and regulation of it. Republicans believe that the current practices are unfair and disproportionately target their voices, whereas democrats generally are in favor of tighter regulation [@keyissues]. Another key issue important to voters and the candidates is abortion. As former president, he supported restrictions on abortion access and advocated for policies that align with the conservative movement’s opposition to abortion rights [@abortionstance]. On the other hand, Harris has been a key supporter in the pro-choice movement and has been an advocate for protecting and expanding access to abortion services, as well as female autonomy [@harrisviews]. The outcome of this election will have profound consequences for various legislative policies and the future direction of the United States. 

To forecast the 2024 United States presidential election, a generalized linear model and Bayesian model were built. These models will help us predict who will win the election based on the electoral college system. A key finding from our model is that we predict Kamala Harris to win the presidential election with 265 electoral college votes. This would be a historic win, as she would be the first woman to become US president, a significant milestone in American politics. One drawback of our model stems from representativeness of the dataset, as it does not include all 50 states in the polls, which may impact the electoral college votes. 

This paper is broken down into various sections, including Data, Modeling, Results, Discussion, Conclusion, and Appendices. This paper uses data made available by FiveThirtyEight [@538data] which compiles individual polling surveys based on state and methodology. @sec-data explores the data, highlighting key aspects that may be useful to future policymakers or campaign strategists, as well as details the variables present in the dataset. @sec-model presents the models that were built and used to forecast the election. @sec-results details the conclusions of our model and @sec-discussion explores possible implications and insights of our conclusions. @sec-appendices include an idealized methodology and survey that we could hypothetically run, with the task of forecasting the US presidential election. This section also includes an in-depth analysis of one specific pollster’s methodology found within the larger dataset. 

# Data {#sec-data}
The dataset used was obtained through FiveThirtyEight Interactives [@538data] and is focused on the United States presidential general polls for 2024. The polling data extracted utilize the "pool of polls" method, which combines multiple polling results into a single estimate. By aggregating data from several polls, this method aims to create a more stable and reliable measure of public opinion by reducing the impact of outliers, sampling error, and individual poll biases. This dataset is crucial to help us build a model to forecast the 2024 US Presidential election and can help us analyze key features in voter habits for future political analysis. Note that polling data collection stopped on October 19. Our model’s results are based solely on data available as of that date and do not incorporate any subsequent polling updates.

There were two other potential datasets that could have been used, titled “Presidential Polling Averages” and “President Primary Polls”, both found through FiveThirtyEight [@538]. The “Presidential Polling Averages” dataset only included data from the Biden versus Trump election in 2020 and was not updated to include data for the upcoming 2024 election and therefore inadequate. The “Presidential Primary Polls” dataset included very similar information as our chosen dataset, however, it included candidates that have since dropped out or were not major running candidates, such as Nikki Haley and Michelle Obama. It includes observations that are unnecessary and creates noise, therefore we did not choose this dataset either. 

The variables used in the dataset include pollster name, pollster weight, method, state, sample size, pollscore, collection/end date, transparency score, candidate, support percentage, election date, days to election, initial weight, weight, and poll region. Pollster Name indicates which pollster the individual poll came from and the weight is assigned by FiveThirtyEight depending on sample size and if they have multiple polls out in a short time to adjust for any bias. Method is the way the poll was deployed, including but not limited to live phone, online panel, and text-to-web. State indicates what state the poll was conducted and sample size is the size of the poll. The pollscore is the rating FiveThirtyEight gives each indidivual poll, on factors such on ethical and methodological elements.The candidate variable indicates the candidate a certain percentage of people in the poll voted for and "support percentage” represents that specific number. The election date and days to election variables indicate how far out the poll was conducted with respect with the election date of November 5, 2024. We also reorganized the dataset to include a poll region, which divides the US into geographical regions such as rust belt, northeast, etc. The table in @sec-app-table details the first few observations of the cleaned dataset, which we used to build our model. 

For further analysis, the cleaned dataset was separated into two different datasets by beach name, for simplicity purposes. Data was analyzed through the R programming software [@citeR] and packages such as tidyverse [@tidyverse], ggplot2 [@ggplot2], knitr [@knitr], and dplyr [@dplyr] were used to help download, clean, simulate, analyze, and test the data. 

Some pollsters are included in the dataset more than others based on the frequency of their conducted poll surveys and if they align with FiveThirtyEight’s guidelines, which can be seen in @fig-1. @fig-1 highlights the distribution of the top 25 pollsters and how frequently they appear in the dataset, with Morning Consult being the most popular pollster with almost 500 appearances. Noting which pollsters are more trustworthy and provide reliable data is important for evaluating the quality of future analyses.

```{r}
#| fig-cap: Top 25 pollsters in overall polling data
#| echo: false
#| warning: false
#| message: false

pollster_counts <- cleaned_poll_data |>
  count(pollster, name = "n") %>%
  arrange(desc(n)) 

top_25_pollsters <- pollster_counts |>
  slice_head(n = 25)  

ggplot(top_25_pollsters, aes(x = reorder(`pollster`, -n), y = n)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "Pollster", y = "Number of Appearances", title = "Top 25 Pollsters") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
```
\newpage

 @fig-2 details the frequency of various polling methods used in the individual polling data, showing online panels are the most popular methodology used to deploy these polls, followed by live phone. The polling method plays a crucial role in reducing certain response biases. For instance, if the poll is conducted via an online panel with anonymous responses, participants may feel more comfortable expressing their true voting intentions, potentially reducing social desirability bias.
 

```{r}
#| label: fig-2
#| fig-cap: Frequency of Various Polling Methods used by FiveThirtyEight in their "pool of polls"
#| echo: false
#| warning: false
#| message: false

polling_method_counts <- cleaned_poll_data |>
  count(method, name = "n") |>
  arrange(desc(n))

top_25_methods <- polling_method_counts |>
  slice_head(n = 25) 

ggplot(top_25_methods, aes(x = reorder(`method`, -n), y = n)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Polling Method", y = "Number of Appearances", title = "Frequency of Polling Methods") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 5))
```
\newpage

Finally, @fig-3 shows the number of votes per candidate. As expected, Harris and Trump have the highest number of votes, with Harris having slightly more votes based on the surveyed polls than Trump. Other candidates with a noticeable number of votes in the graph include Robert F. Kennedy and Jill Stein. However, their totals are significantly lower than those of Harris and Trump, making them likely insignificant in the election. It is also important to mention that Biden still appears in these polls, and therefore in @fig-3, due to the lag time in poll data processing by FiveThirtyEight. However, since he has dropped out of the race, he will not be included in our model.

```{r}
#| label: fig-3
#| fig-cap: Number of Votes per Candidate. This reflects the popular vote for each candidate and does not account for the electoral college sytem. 
#| echo: false
#| warning: false
#| message: false

cleaned_poll_data <- cleaned_poll_data |> 
  mutate(sample_size = ifelse(is.na(sample_size), 0, sample_size))

votes = cleaned_poll_data$support / 100 * cleaned_poll_data$sample_size

poll_summary <- cleaned_poll_data |>
  group_by(candidate) |>
  summarize(votes = sum(votes, na.rm = TRUE))
poll_summary <- poll_summary |>
  filter(!is.na(candidate), !is.na(votes))

ggplot(cleaned_poll_data, aes(x = candidate, y = votes, fill = candidate)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of Votes per Candidate", 
       x = "Candidate", 
       y = "Number of Votes") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10), 
        legend.position = "none")
```
\newpage

# Model {#sec-model}


## Model set-up

We built three unique models, this allows us to choose the one that most closely fits the data historically, and weigh the pros and cons of each model to decide which one works best for us. This section will go through the process of how each of these models was developed and how we selected our final model.  The first model was a conventional GLM, and the second was a Bayesian model with various differences and caveats.

For the GLM model, we began by defining the 538 political regions [REF], and we fit a Harris and Trump GLM model for each of those regions. The intuition behind this is that voters in these regions are likely to vote in similar ways, therefore by pooling their preferences together we can get a more accurate model than one built at the State level. In other words, there would be too much noise in the State level model. Furthermore, some states have little to no polling data making the building of a model in these cases impossible (NOTE: how do we deal with these states later if there's no polling?). We then apply the polling data to these fitted regional models at the state level, to gauge Harris and Trump support. This allows us to predict the winner of each state, which informs us how many electoral college votes a candidate will get, and thus the winner of the election.

The Bayesian model is necessarily more complicated. A major advantage of a Bayesian model is the ability to include prior information, encoded in the aptly named Prior. In the US elections states often vote very similarly [REF] across decades. We began to reflect this by classifying all states as either, Deep Red, Light Red, Swing, Light Blue, Dark Blue, to reflect their historical voting bias based on this list [REF]. With the Priors encoded we fit a Harris and Trump model using Bayes R package [REF]. We then synthesized a testing dataset for all the states, and used this data to get predictions of support for both candidates in each State. As was done in the previous model this gave us predictions on who would win each state, which allowed us to calculate the elector votes each candidate was likely to get and therefore the winner of the election.

### Model justification



# Results {#sec-results}

MODEL NOT PERFECT WRITE AFTER DONE

The GLM predicts Harris winning with [EV VOTES], with Trump only winning [EV VOTES]. The Bayesinal model also predicts a Harris victory with [EV VOTES] and Trump with [EV VOTES].(Maybe better as a table). 


# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}


## Second discussion point

## Third discussion point

## Weaknesses and next steps


\newpage

\appendix

# Appendix {#sec-appendices}

## Analysis into a Pollster's Methodology

One particular poll within our data sample is one conducted between October 11-14 by Beacon Research and Shaw & Company Research (cite Fox article). Targeting the sample frame of registered American voters, this poll collected data on 1,110 participants’ responses on 51 questions through either live phonecall interviews or an online survey. The sample was recruited by applying the probability proportionate to size method on the nationwide voter file of registered voters’ phone numbers, meaning that the contacted individuals would be proportionally representative of the number of voters per state (cite Fox article). This ensures that the voices represented by poll results would match the ones involved with the real election as much as possible. 

The key finding from this poll is that 48% of participants favored Harris while 50% favored Trump, with the lead being consistent in the larger sample of registered voters and smaller subsample of likely voters. Despite this, responses also indicate that Harris is narrowly leading in seven swing states, meaning that Democrats could potentially win by electoral college while losing the popular vote (cite Fox article). This report also notes that current results are Trump’s highest approval ratings since Biden dropped out of the race, while support for Harris is at its lowest. 

One strength of this questionnaire is that information regarding the respondent’s confidence level and commitment level was also collected. With questions such as “How often do you make a point to read or listen to the news?” and “Are you certain to support that candidate, or do you think you may change your mind and support someone else?”, this poll is able to gain a more indepth view of how easily these participants may be swayed in the time between the polling and the real election (cite Fox article). As well, probabilistic statistical models based on past voting history, interest in current election, age, education, race, ethnicity, church attendance, and marital status were used to predict the respondents’ likeliness to vote; interestingly, results found that the results for the full sample vs subsample of 870 likely voters varied by a ±3%, which can be quite significant given how tight the race is currently (cite Fox article). 

On the other hand, one potential weakness of this poll is that it was sponsored by Fox News, a news site that has historically been Republican-leaning. Though from the reported methodology alone, no evident biasing of the pollster can be observed, this potential source of biased reporting must be noted as it can affect the type of analyses that occurred and which key findings are the focus of news reports. As well, another potential issue is the lack of indication regarding how non-responses of “Don’t know” were handled during analysis (cite Fox article). This is a critical area to pay attention to as it is an option offered on every question, selected by up to 4% of participants on key questions such as “If the presidential election were today, how would you vote?” (cite Fox article).

## Idealized Methodology and Survey

## Table Detailing First Few Observations of Dataset {#sec-app-table}

```{r}
#| label: tbl-1
#| tbl-cap: First few observations of cleaned data set
#| echo: false

first_table <- cleaned_poll_data[, c("pollster", "numeric_grade", "pollscore", 
                                       "end_date", "transparency_score", 
                                       "question_id", "method")]

kable(head(first_table, 5), col.names = names(first_table), 
      booktabs = TRUE)

second_table <- cleaned_poll_data[, c("state", "sample_size", "candidate", 
                                        "support", "election_date", 
                                        "days_to_election", "initial_weight", 
                                        "weight", "pol_region")]

kable(head(second_table, 5), col.names = names(second_table), 
      booktabs = TRUE) 

```

```{=latex}
\newpage\newpage

```
# References


