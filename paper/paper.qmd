---
title: "Forecasting the United States 2024 Presidential Election"
subtitle: "Kamala Harris wins 60th presidency with 279 Electoral College Votes"
author: 
  - Robert Ford
  - Michelle Ji
  - Cher Ning
thanks: "Code and data are available at: https://github.com/Ford-Robert/us-presidential-election."
date: today
date-format: long
abstract: "This report analyzes compiled polling surveys for the 2024 U.S. presidential election using FiveThirtyEight data [@538data] and the 'pool of polls' method. From the analysis, bayesian and generalized linear models were built to forecast the outcome of the presidential election based on popular vote and the electoral college system. The models forecast Kamala Harris as the winner of election, winning 279 electoral college votes versus the 258 votes Donald Trump acquires. Election forecasting is crucial for informing voters, guiding campaign strategies, and engaging the public in the electoral process. Additionally, it helps predict potential policy shifts and holds political institutions accountable, contributing to a more transparent and informed democracy."
format:
  pdf:
    prefer-html: true
  html: default
header-includes:
  - \usepackage{geometry}
  - \geometry{margin=0.75in} 
number-sections: true
bibliography: references.bib
---



```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(kableExtra)
library(ggplot2)
library(here)
library(kableExtra)
library(usmap)      # For US maps
library(ggplot2)
library(webshot2)
library(knitr)
opts_knit$set(webshot = TRUE)


plot_path <- here::here("other", "plots", "election_map.png")

#read in cleaned data
cleaned_poll_data <-
  read_csv(file = here("data/cleaned_poll_data.csv"), 
           show_col_types = FALSE)
```


# Introduction {#sec-intro}

Every four years, the United States presidential election occurs and is one of the most significant political events internationally. The complex process of the election involves both the popular and electoral college system. The candidate that receives the popular vote by the voters wins the electoral votes for that state [@electoralcollege]. After the popular vote is accounted for, the candidate who receives the majority of the electoral votes from all states wins the presidential election. The number of electoral votes varies by state and is proportional to each state’s respective population [@electoralcollege]. 

Specifically for the 2024 presidential election, the top candidates include Donald Trump and Kamala Harris, both with differing opinions on key topics such as immigration, technology, abortion, and transatlantic affairs. For example, regarding technology, both parties are concerned with the rapid progression of artificial intelligence’s capabilities but differ in the response and regulation of it. Republicans believe that the current practices are unfair and disproportionately target their voices, whereas democrats generally are in favor of tighter regulation [@keyissues]. Another key issue important to voters and the candidates is abortion. As former president, he supported restrictions on abortion access and advocated for policies that align with the conservative movement’s opposition to abortion rights [@abortionstance]. On the other hand, Harris has been a key supporter in the pro-choice movement and has been an advocate for protecting and expanding access to abortion services, as well as female autonomy [@harrisviews]. The outcome of this election will have profound consequences for various legislative policies and the future direction of the United States. 

To forecast the 2024 United States presidential election, a generalized linear model and Bayesian model were built. These models will help us predict who will win the election based on the electoral college system. A key finding from our model is that we predict Kamala Harris to win the presidential election with 265 electoral college votes. This would be a historic win, as she would be the first woman to become US president, a significant milestone in American politics. One drawback of our model stems from representativeness of the dataset, as it does not include all 50 states in the polls, which may impact the electoral college votes. 

This paper is broken down into various sections, including Data, Modeling, Results, Discussion, Conclusion, and Appendices. This paper uses data made available by FiveThirtyEight [@538data] which compiles individual polling surveys based on state and methodology. @sec-data explores the data, highlighting key aspects that may be useful to future policymakers or campaign strategists, as well as details the variables present in the dataset. @sec-model presents the models that were built and used to forecast the election. @sec-results details the conclusions of our model and @sec-discussion explores possible implications and insights of our conclusions. @sec-appendices include an idealized methodology and survey that we could hypothetically run, with the task of forecasting the US presidential election. This section also includes an in-depth analysis of one specific pollster’s methodology found within the larger dataset. 

# Data {#sec-data}
The dataset used was obtained through FiveThirtyEight Interactives [@538data] and is focused on the United States presidential general polls for 2024. The polling data extracted utilize the "pool of polls" method, which combines multiple polling results into a single estimate. By aggregating data from several polls, this method aims to create a more stable and reliable measure of public opinion by reducing the impact of outliers, sampling error, and individual poll biases. This dataset is crucial to help us build a model to forecast the 2024 US Presidential election and can help us analyze key features in voter habits for future political analysis. Note that polling data collection stopped on October 19. Our model’s results are based solely on data available as of that date and do not incorporate any subsequent polling updates.

There were two other potential datasets that could have been used, titled “Presidential Polling Averages” and “President Primary Polls”, both found through FiveThirtyEight [@538]. The “Presidential Polling Averages” dataset only included data from the Biden versus Trump election in 2020 and was not updated to include data for the upcoming 2024 election and therefore inadequate. The “Presidential Primary Polls” dataset included very similar information as our chosen dataset, however, it included candidates that have since dropped out or were not major running candidates, such as Nikki Haley and Michelle Obama. It includes observations that are unnecessary and creates noise, therefore we did not choose this dataset either. 

The variables used in the dataset include pollster name, pollster weight, method, state, sample size, pollscore, collection/end date, transparency score, candidate, support percentage, election date, days to election, initial weight, weight, and poll region. Pollster Name indicates which pollster the individual poll came from and the weight is assigned by FiveThirtyEight depending on sample size and if they have multiple polls out in a short time to adjust for any bias. Method is the way the poll was deployed, including but not limited to live phone, online panel, and text-to-web. State indicates what state the poll was conducted and sample size is the size of the poll. The pollscore is the rating FiveThirtyEight gives each indidivual poll, on factors such on ethical and methodological elements.The candidate variable indicates the candidate a certain percentage of people in the poll voted for and "support percentage” represents that specific number. The election date and days to election variables indicate how far out the poll was conducted with respect with the election date of November 5, 2024. We also reorganized the dataset to include a poll region, which divides the US into geographical regions such as rust belt, northeast, etc. The table in @sec-app-table details the first few observations of the cleaned dataset, which we used to build our model. 

For further analysis, the cleaned dataset was separated into two different datasets by beach name, for simplicity purposes. Data was analyzed through the R programming software [@citeR] and packages such as tidyverse [@tidyverse], ggplot2 [@ggplot2], knitr [@knitr], and dplyr [@dplyr] were used to help download, clean, simulate, analyze, and test the data. 

Some pollsters are included in the dataset more than others based on the frequency of their conducted poll surveys and if they align with FiveThirtyEight’s guidelines, which can be seen in @fig-1. @fig-1 highlights the distribution of the top 25 pollsters and how frequently they appear in the dataset, with Morning Consult being the most popular pollster with almost 500 appearances. Noting which pollsters are more trustworthy and provide reliable data is important for evaluating the quality of future analyses.

```{r}
#| label: fig-1
#| fig-cap: Top 25 pollsters in overall polling data
#| echo: false
#| warning: false
#| message: false

pollster_counts <- cleaned_poll_data |>
  count(pollster, name = "n") %>%
  arrange(desc(n)) 

top_25_pollsters <- pollster_counts |>
  slice_head(n = 25)  

ggplot(top_25_pollsters, aes(x = reorder(`pollster`, -n), y = n)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "Pollster", y = "Number of Appearances", title = "Top 25 Pollsters") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 6))
```
\newpage

 @fig-2 details the frequency of various polling methods used in the individual polling data, showing online panels are the most popular methodology used to deploy these polls, followed by live phone. The polling method plays a crucial role in reducing certain response biases. For instance, if the poll is conducted via an online panel with anonymous responses, participants may feel more comfortable expressing their true voting intentions, potentially reducing social desirability bias.
 

```{r}
#| label: fig-2
#| fig-cap: Frequency of Various Polling Methods used by FiveThirtyEight in their "pool of polls"
#| echo: false
#| warning: false
#| message: false

polling_method_counts <- cleaned_poll_data |>
  count(method, name = "n") |>
  arrange(desc(n))

top_25_methods <- polling_method_counts |>
  slice_head(n = 25) 

ggplot(top_25_methods, aes(x = reorder(`method`, -n), y = n)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Polling Method", y = "Number of Appearances", title = "Frequency of Polling Methods") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 5))
```
\newpage

Finally, @fig-3 shows the number of votes per candidate. As expected, Harris and Trump have the highest number of votes, with Harris having slightly more votes based on the surveyed polls than Trump. Other candidates with a noticeable number of votes in the graph include Robert F. Kennedy and Jill Stein. However, their totals are significantly lower than those of Harris and Trump, making them likely insignificant in the election. It is also important to mention that Biden still appears in these polls, and therefore in @fig-3, due to the lag time in poll data processing by FiveThirtyEight. However, since he has dropped out of the race, he will not be included in our model.

```{r}
#| label: fig-3
#| fig-cap: Number of Votes per Candidate. This reflects the popular vote for each candidate and does not account for the electoral college sytem. 
#| echo: false
#| warning: false
#| message: false

cleaned_poll_data <- cleaned_poll_data |> 
  mutate(sample_size = ifelse(is.na(sample_size), 0, sample_size))

votes = cleaned_poll_data$support / 100 * cleaned_poll_data$sample_size

poll_summary <- cleaned_poll_data |>
  group_by(candidate) |>
  summarize(votes = sum(votes, na.rm = TRUE))
poll_summary <- poll_summary |>
  filter(!is.na(candidate), !is.na(votes))

ggplot(cleaned_poll_data, aes(x = candidate, y = votes, fill = candidate)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of Votes per Candidate", 
       x = "Candidate", 
       y = "Number of Votes") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 10), 
        legend.position = "none")
```
\newpage

# Model {#sec-model}

      
To predict state level support and calculate the expected Electoral Votes (EV) for each candidate in the upcoming US election, we employed a Bayesian linear regression model. The model is mathematically specified as follows:

$$
\text{Support}_i = \beta_0 + \beta_1 \times \text{Sample Size}_i + \beta_2 \times \text{Days to election}_i + \beta_3 \times \text{Transparency Score}_i + \beta_4 \times \text{Pollscore}_i + \gamma \times \text{State}_i + \epsilon_i
$$

- **support<sub>i</sub>**  
  *Definition:* The support level for candidate \( i \) in a given poll.  
  *Justification:* Measures the proportion of respondents supporting candidate \( i \), providing insight into their current standing.

- **sample\_size<sub>i</sub>**  
  *Definition:* Represents the number of respondents in poll \( i \).  
  *Justification:* Larger sample sizes generally yield more accurate estimates of support, reducing sampling variability.

- **days\_to\_election<sub>i</sub>**  
  *Definition:* Denotes the number of days remaining until the election when poll \( i \) was conducted.  
  *Justification:* Accounts for temporal proximity to the election, capturing potential fluctuations in support as the election approaches.

- **transparency\_score<sub>i</sub>**  
  *Definition:* A numerical score reflecting the pollster’s transparency regarding their methodology, ranging up to 10, with higher scores indicating greater transparency.  
  *Justification:* Higher transparency scores may correlate with the reliability and credibility of poll results, influencing voter trust.

- **pollscore<sub>i</sub>**  
  *Definition:* A numeric value representing the reliability and bias of the pollster, where negative values denote better reliability.  
  *Justification:* Accounts for systematic deviations in poll results based on pollster performance, ensuring more accurate support estimates.

- **state<sub>i</sub>**  
  *Definition:* Captures state-specific effects as fixed effects.  
  *Justification:* Allows the model to account for regional variations in support that are not explained by other predictors, incorporating state-specific nuances.

- **ϵ<sub>i</sub>**  
  *Definition:* The error term, assumed to follow a normal distribution.  
  *Justification:* Represents unexplained variability in the model, ensuring that the residuals meet the assumptions of the statistical analysis.
  

Variable Definitions:

- **Sample Size (\(\text{sample\_size}\))**: The size of the poll is included as larger samples generally provide more accurate estimates of support, reducing sampling variability.
  
- **Days to Election (\(\text{days\_to\_election}\))**: This variable accounts for the temporal proximity to the election, as support levels may fluctuate as the election approaches, capturing trends in voter sentiment over time.
  
- **Transparency Score (\(\text{transparency\_score}\))**: A higher transparency score indicates greater disclosure of poll methodology, potentially correlating with the reliability and credibility of the poll results.
  
- **Pollscore (\(\text{pollscore}\))**: This score represents the inherent bias and error of the pollster, with lower (more negative) values indicating higher reliability. It accounts for systematic deviations in poll results based on historical pollster performance [REF 538 METHOD].
  
- **State (\(\text{state}\))**: Including state as a fixed effect allows the model to account for regional variations in support that are not captured by other predictors, ensuring state-specific nuances are incorporated into the support estimates.

An alternative approach considered was modeling State as a random effect to account for unobserved heterogeneity across states. However, given the focus on specific state-level predictions and the availability of sufficient data per state, fixed effects are chosen in this case. Ideally we would fit both models and use diagnostics to choose which has lower bais and variance, and thus better predictive quality. Additionally, simpler models excluding variables like transparency_score and pollscore were evaluated but found inadequate in capturing the state-by-state differences in the transparency and reliability of the polls, potentially leading to biased support estimates.

  
Process:

For each candidate and state, we aggregated polling data by calculating the mean values of each predictor. For example, here is the mathematical notation of Mean Days to Election, this value was calculated for each state for both candidates:



$\text{Mean Days to Election}_s = \frac{1}{N_s} \sum_{i=1}^{N_s} \text{Days to Election}_i$




where \(N_s\) is the number of polls for state \(s\).

Averaging predictors per state smooths out poll-to-poll variability and provides a representative set of predictors for each state, allowing use to make reliable state-level predictions. Instead of averaging, a training/testing split or regional aggregations based on 538's political regions could have been employed. However, a training/testing split is beyond the scope of this paper, and using political regions would have complicated the derivation of the model.


Using the averaged state level predictors, we generated posterior predictions by drawing 1,000 samples from the posterior distributions of the model parameters. These predictions simulate 1,000 possible election outcomes, and by taking the proportion of victories for Harris and Trump we estimate the probability each candidate has of winning the election. To generate an election map, we simply take the average outcome of each state across the 1,000 simulations. Alternative methods could include using point estimates from the posterior mean; however, simulating multiple outcomes offers a more comprehensive assessment of uncertainty and variability in election outcomes.


For states lacking recent polling data, we incorporated historical averages of Democratic and Republican support from elections since 2000. This decision is based on the assumption that certain states are very unlikely to change their voting patterns, reducing the necessity for current polling data. The ten states that do not have polling data [REF] have not changed parties in at least the last 20 plus years. This may be why they do not have polling data, as it would be a waste of resources for agencies to poll them. Alternatively, imputation methods or political regional averages could have been used, but historical averages are used for their simplicity and relevance.


The Bayesian models were implemented using the `rstanarm` package in R, which interfaces with Stan for efficient Markov Chain Monte Carlo (MCMC) sampling. Data manipulation and visualization were conducted using the `tidyverse` suite of packages, while model diagnostics leveraged `bayesplot` and other related packages. This combination of tools facilitated a streamlined workflow for model fitting, prediction, and validation.


## Diagnostics {#sec-diagnostics}

Comprehensive diagnostics were performed to assess model convergence, fit, and predictive performance. Graphs and more details can be found in the relevant appendices. We evaluated model convergence using the R-hat statistic and trace plots. All R-hat values for model parameters were below 1.1, indicating satisfactory convergence. Trace plots revealed well-mixed chains without discernible trends, further supporting the reliability of the MCMC sampling process [REF]. 

Posterior predictive checks were conducted to assess the model's ability to replicate observed data. Density overlay plots for both Trump and Harris models indicated reasonable fits, although some discrepancies were noted near the peaks of the distributions. Specifically, the Trump model's replicated data tended to be slightly smaller around the peak, while the Harris model exhibited more extreme differences at the peak. Residual plots appeared randomly scattered, suggesting no major systematic biases, although some clumping was observed, indicating areas where the model may fit less effectively [REF].

Residual plots, depicting residuals versus fitted values, showed notable clumping in the central region for both models, along with vertical lines. This pattern may indicate unmodeled heterogeneity or data limitations, suggesting areas where the model's fit could be improved. Despite these observations, the overall residual distribution did not reveal significant systematic errors, supporting the model's general adequacy.

Ideally several models would be created then using model selection techniques would be used to determine the best model for predicting the outcome of the US election. Due to time constraints the folling models were considered but not implemented. A set of Bayesian models with state as a random effect and models excluding specific predictors like transparency_score. More complex models with additional interaction terms or non-linear components were also considered

#### Assumptions and Limitations

The model operates under several key assumptions:

1. **Linearity:** The relationship between predictors and support is linear.
2. **Normality of Residuals:** The error terms follow a normal distribution.
3. **Independence:** Observations are independent given the predictors.
4. **Stable Partisan Leanings:** Historical averages adequately represent states without current polling data.


**Limitations:**

- **Model Misspecification:** If non-linear relationships exist between predictors and support, the linear model may not capture these dynamics effectively.
- **Reliance on Historical Data:** Using historical averages for certain states may not account for recent political shifts or emerging trends.
- **Residual Clumping:** Observed clumping in residual plots suggests potential areas for model refinement, such as incorporating additional predictors or interaction terms.


The final Bayesian linear regression model balances complexity and interpretability, incorporating relevant predictors to capture poll reliability and state-specific effects while maintaining computational efficiency. The inclusion of transparency_score and pollscore enhances the model's ability to account for poll quality, while fixed state effects ensure accurate regional support estimates. Validation through convergence diagnostics, posterior predictive checks, and residual analysis confirms the model's robustness and reliability within its assumptions.


All analyses were conducted using R (version 4.2.1) with the following key packages:

- **tidyverse:** For data manipulation and visualization.
- **rstanarm:** For Bayesian model fitting using Stan.
- **brms:** Alternative package for Bayesian regression modeling.
- **bayesplot:** For comprehensive model diagnostics and visualization.



# Results {#sec-results}

Our model predicts that Harris has a 68.8% chance of winning the US presidential election. While Trump only has a 30.1% chance of winning. There is also a 1.1% chance of a tie On average across the 1,000 simulations Harris wins 279.21 Electoral Votes, while Trump wins on average 258.79 votes.

```{r}
#| echo: false
#| warning: false
#| message: false
election_results <- data.frame(
  Metric = c("Chance of Winning", "Average Electoral Votes"),
  Harris = c("68.8%", "279.21"),
  Trump = c("30.1%", "258.79"),
  stringsAsFactors = FALSE
)

election_results %>%
  kable("html", caption = "Election Prediction Results") %>%
  kable_styling(
    "bordered",
    full_width = FALSE,
    position = "center"
  ) %>%
  add_header_above(c(" " = 1, "Candidates" = 2)) %>%
  row_spec(0, bold = TRUE) # Makes the header row bold

# Display a nicely formatted table
kable(election_results, caption = "Election Prediction Results")

```

Based on the simulated elections, this map illustrates the most likely winner of each state. In this scenario Harris wins 277 Electoral Votes, and Trump wins 262.[Appendix]

```{r}
#| echo: false
#| warning: false
#| message: false
knitr::include_graphics(plot_path)

```
The results of the US elections in large part hinge on the direction of the swing states. A swing state is a state that holds a significant number of electoral votes and could reasonable be won by either Trump or Harris. [FIG] shows the probability that both candidates have of winning each of the 7 swing states.

```{r plot-probabilities, echo=FALSE, fig.width=8, fig.height=6}
# Reshape the data for plotting
swing_long <- swing_probs %>%
  pivot_longer(cols = c("Trump", "Harris"), names_to = "Candidate", values_to = "Probability")

custom_colors <- c("Trump" = "#DD1717", "Harris" = "#0F4392")

# Create the bar plot
ggplot(swing_long, aes(x = state, y = Probability, fill = Candidate)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = custom_colors) +
  labs(
    title = "Probability of Winning Swing States",
    x = "State",
    y = "Probability (%)",
    fill = "Candidate"
  ) +
  theme_minimal() +
  theme(
    text = element_text(size = 12),
    plot.title = element_text(hjust = 0.5)
  )

```

# Discussion {#sec-discussion}

## Implications and Potential Weaknesses {#sec-disc-imp}

Our model predicting the U.S. election carries important social and political implications. Accurate forecasts can shape voter perceptions, potentially affecting turnout by leading some individuals to feel their votes are less crucial if a particular outcome seems likely. Additionally, these predictions inform campaign strategies, prompting candidates to focus resources on undecided voters in critical swing states, which play a pivotal role in tight elections like the upcoming 2024 race. For instance, our model anticipates that key swing states such as Pennsylvania, Michigan, and Wisconsin will award their electoral votes to Kamala Harris, contributing to her victory. However, the forecast indicates that Harris is expected to win by narrow margins of approximately 1.98%, 1.47%, and 1.46% in these states, respectively.

Our model offers valuable insights into the landscape of the current U.S. election; however, it does face a few limitations. One of the primary challenges stems from gaps in our dataset, specifically the absence of polling data for several states. When the polling data was collected and compiled by @538, it did not comprehensively include every state, leading to missing data points that affect our predictions. Our model relies on the electoral college system, where each state’s popular vote determines its allocation of electoral votes, ultimately deciding the election’s outcome. Missing data from certain states introduces an incomplete representation of the voting scene, affecting the accuracy of our predictions. Each state often exhibits unique voting behaviors and excluding certain states can introduce a bias in our model. This is especially problematic if the omitted states are swing states or tend to have historically unpredictable voting patterns, as these states can play a decisive role in election outcomes. Moreover, missing data for larger states further exacerbates the issue by potentially leading to a miscalculation of the Electoral College outcome. States with significant electoral votes carry substantial weight, and without accurate polling information from them, our model may struggle to forecast the election winner effectively. 

Another limitation of our model is that we stopped pulling new poll data from @538 as of October 19, 2024. Consequently, the model does not account for any last-minute events that could have impacted voter opinions from then until election day. This could potentially lead to misleading predictions if there has been a significant change in public sentiment. Furthermore, last-minute shifts in public opinion could result in different voter turnout than initially anticipated or introduce polling response biases, which predictive models may struggle to capture if they are based primarily on earlier data.

## Next Steps {#sec-disc-next}

Consequently, our forecast suggests that candidates should concentrate their efforts on swing states, as increased campaigning in these areas could significantly impact voter turnout and the popular vote. Additionally, enlisting high-profile figures or celebrities, like Elon Musk or LeBron James—who have recently endorsed Trump and Harris, respectively—could enhance their appeal in these swing states. These endorsements would help candidates reach diverse and niche demographics, broadening their voter base and potentially swaying undecided voters.

## Betting Markets {#sec-disc-bet}



\newpage

\appendix

# Appendix {#sec-appendices}


## Analysis into a Pollster's Methodology {#sec-pollster-analysis}

One particular poll within our data sample is one conducted between October 11-14 by Beacon Research and Shaw & Company Research [@fox]. Targeting the sample frame of registered American voters, this poll collected data on 1,110 participants’ responses on 51 questions through either live phonecall interviews or an online survey. The sample was recruited by applying the probability proportionate to size method on the nationwide voter file of registered voters’ phone numbers [@fox]. This sampling method is a type of probability sampling in which each unit's chance of being included is dependent upon their size, a measure that is based off of some characteristic that is known about every single unit and often related to the main variable of interest. By giving a higher probability of inclusion to units of greater importance based on its size during sampling, a more accurate estimate can be obtained [@Latpate2021]. In the case of this poll, the number of voters per state region was used to determine the proportion of individuals contacted [@fox]. This ensures that a greater number of residents in larger states, such as California, would be contacted compared to smaller states, such as Hawaii. This method of sampling allows for a better match between the voices represented by poll results to the ones involved with the real election. 

The key finding from this poll is that 48% of participants favored Harris while 50% favored Trump, with the lead being consistent in the larger sample of registered voters and smaller subsample of likely voters. Despite this, responses also indicate that Harris is narrowly leading in seven swing states, meaning that Democrats could potentially win by electoral college while losing the popular vote  [@fox]. This report also notes that current results are Trump’s highest approval ratings since Biden dropped out of the race, while support for Harris is at its lowest. 

One strength of this questionnaire is that information regarding the respondent’s confidence level and commitment level was also collected. With questions such as “How often do you make a point to read or listen to the news?” and “Are you certain to support that candidate, or do you think you may change your mind and support someone else?”, this poll is able to gain a more indepth view of how easily these participants may be swayed in the time between the polling and the real election  [@fox]. As well, probabilistic statistical models based on past voting history, interest in current election, age, education, race, ethnicity, church attendance, and marital status were used to predict the respondents’ likeliness to vote; interestingly, results found that the results for the full sample vs subsample of 870 likely voters varied by a ±3%, which can be quite significant given how tight the race is currently  [@fox]. 

On the other hand, one potential weakness of this poll is that it was sponsored by Fox News, a news site that has historically been Republican-leaning. Though from the reported methodology alone, no evident biasing of the pollster can be observed, this potential source of biased reporting must be noted as it can affect the type of analyses that occurred and which key findings are the focus of news reports. As well, another potential issue is the lack of indication regarding how non-responses of “Don’t know” were handled during analysis  [@fox]. This is a critical area to pay attention to as it is an option offered on every question, selected by up to 4% of participants on key questions such as “If the presidential election were today, how would you vote?” [@fox].

## Idealized Methodology and Survey

In an ideal world, where a $100k in funds and all necessary resources could be obtained from a neutral source for the purpose of polling the population, the idealized methodology for a survey that aims to forecast the results of the US election should be one that uses quota sampling and the probability proportionate to size method to target the states of interest specifically. Historically, certain states have very strong and consistent party preferences; for example, we can be almost entirely certain even without conducting any current research that California would be voting Democrat, simply because this has been how they voted in the past eight elections [@blueredstate]. Out of the 51 states, there are 20 states which voted for the same party each time in the past nine elections and therefore there is a high probability that the pattern will be upheld with this year's election [@blueredstate]. On the other end of the spectrum, there are seven states which have voted for each party three of more times within the last nine elections——these would be the states of greater interest to us [@blueredstate]. 

Using the non-probability sampling method of quota sampling, these swing states will first be selected. This targetted sampling process allows us to focus our polling efforts on gathering more data from the areas where there is higher uncertainty, but the tradeoff is bias is easily introduced with the assumptions we are making, potentially impacting the accuracy of our forecast [@quotasampling]. This means that more work is required to adjust for these biases while also minimizing the inflation of variance [@quotasamping].

Next, within these states, probability proportionate to size will be used to select participants from the nationwide file of registered voters to ensure that the number of people polled is proportional to the number of voters per region. This is the sampling method used in @fox, as discussed above in @sec-pollster-analysis, and it allows for greater accuracy of prediction due to each unit's strategically adjusted probability of inclusion [@Latpate2021]. 

After the sample has been selected with the above methods, the poll itself will be conducted through a survey sent to the chosen participants in order to reduce interviewer bias, or the effect of the interviewer’s own views on the measured responses, which can affect results when face-to-face or phone interviews are utilized [@citeTB]. As well, to reduce social desirability effect, the survey must emphasize in the beginning that the respondents’ identity will be kept anonymous to the researchers and the final reported data [@citeStantcheva]. 

- questions (wording, order, options)
- treatment of non-response
- offer of incentive

After analysis of poll responses, the votes of the consistent states should be added back into consideration before making the final forecast for election results. 

A sample implementation of such poll, created using Google form, can be found [here](https://forms.gle/ti2rjGGVxBukv9dF6). In this version, the order of questions presented is consistent for all respondents due to the limitations of Google form, but for an idealized methodology with more professional surveying platform, the question order should be randomized when being presented to different respondents. This will help reduce response order bias, which is when the answer of a question is affected by the order in which it appeared in the survey [@citeStantcheva].

## Table Detailing First Few Observations of Dataset {#sec-app-table}

```{r}
#| label: tbl-1
#| tbl-cap: First few observations of cleaned data set
#| echo: false

first_table <- cleaned_poll_data[, c("pollster", "numeric_grade", "pollscore", 
                                       "end_date", "transparency_score", 
                                       "question_id", "method")]

kable(head(first_table, 5), col.names = names(first_table), 
      booktabs = TRUE)

second_table <- cleaned_poll_data[, c("state", "sample_size", "candidate", 
                                        "support", "election_date", 
                                        "days_to_election", "initial_weight", 
                                        "weight", "pol_region")]

kable(head(second_table, 5), col.names = names(second_table), 
      booktabs = TRUE) 

```

```{=latex}
\newpage\newpage

```
\newpage

# References
